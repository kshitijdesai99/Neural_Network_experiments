{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb51f552",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (1738811952.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    The experiment aims to find out if nn can learn to classifiy arithmetic operations.\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: Can a neural network learn to classifiy arithmetic operations?\n",
    "\n",
    "\n",
    "## Objective\n",
    "The experiment aims to find out if nn can learn to classifiy arithmetic operations.\n",
    "\n",
    "## Problem Specification\n",
    "- **Input**: x, y, z\n",
    "- **Output**: can be +,-,*,/\n",
    "- **Task**: Implementation of a neural network that can learn to classify arithmetic operations\n",
    "\n",
    "## Expected Outcome\n",
    "- A neural network can learn to classify arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e630d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different layer size combinations for arithmetic operations classifier\n",
      "======================================================================\n",
      "\n",
      "Testing with first layer: 8 neurons, second layer: 8 neurons\n",
      "  Epoch 0: Train Loss: 1.6969, Val Accuracy: 0.2130\n",
      "  Epoch 50: Train Loss: 1.3582, Val Accuracy: 0.3100\n",
      "  Epoch 100: Train Loss: 1.2877, Val Accuracy: 0.3940\n",
      "  Epoch 150: Train Loss: 1.1695, Val Accuracy: 0.4700\n",
      "× Early stopping at epoch 151\n",
      "  Best validation accuracy: 0.4880\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Division     |    Addition    \n",
      "   7     |    4     |    3     |    Addition     |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Addition     |    Division    \n",
      "\n",
      "Accuracy on examples: 1/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   34.32%\n",
      " LeakyReLU:   32.30%\n",
      "    Linear:   33.38%\n",
      "\n",
      "Total weight magnitude: 1.044358\n",
      "\n",
      "Testing with first layer: 16 neurons, second layer: 8 neurons\n",
      "  Epoch 0: Train Loss: 1.5132, Val Accuracy: 0.2340\n",
      "  Epoch 50: Train Loss: 1.2325, Val Accuracy: 0.3670\n",
      "  Epoch 100: Train Loss: 1.0798, Val Accuracy: 0.6270\n",
      "  Epoch 150: Train Loss: 0.9200, Val Accuracy: 0.7060\n",
      "  Epoch 200: Train Loss: 0.7614, Val Accuracy: 0.7580\n",
      "  Epoch 250: Train Loss: 0.6479, Val Accuracy: 0.7950\n",
      "  Epoch 300: Train Loss: 0.5651, Val Accuracy: 0.8110\n",
      "  Epoch 350: Train Loss: 0.5008, Val Accuracy: 0.8340\n",
      "  Epoch 400: Train Loss: 0.4502, Val Accuracy: 0.8570\n",
      "  Epoch 450: Train Loss: 0.4111, Val Accuracy: 0.8650\n",
      "× Early stopping at epoch 455\n",
      "  Best validation accuracy: 0.8650\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |   Subtraction   |    Division    \n",
      "\n",
      "Accuracy on examples: 3/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   36.41%\n",
      " LeakyReLU:   30.71%\n",
      "    Linear:   32.88%\n",
      "\n",
      "Total weight magnitude: 1.698758\n",
      "\n",
      "Testing with first layer: 12 neurons, second layer: 12 neurons\n",
      "  Epoch 0: Train Loss: 1.3928, Val Accuracy: 0.2640\n",
      "  Epoch 50: Train Loss: 1.1455, Val Accuracy: 0.5440\n",
      "  Epoch 100: Train Loss: 0.9674, Val Accuracy: 0.6800\n",
      "  Epoch 150: Train Loss: 0.7602, Val Accuracy: 0.7840\n",
      "  Epoch 200: Train Loss: 0.6071, Val Accuracy: 0.8290\n",
      "  Epoch 250: Train Loss: 0.5175, Val Accuracy: 0.8560\n",
      "  Epoch 300: Train Loss: 0.4588, Val Accuracy: 0.8600\n",
      "× Early stopping at epoch 308\n",
      "  Best validation accuracy: 0.8620\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   35.01%\n",
      " LeakyReLU:   31.01%\n",
      "    Linear:   33.98%\n",
      "\n",
      "Total weight magnitude: 1.564242\n",
      "\n",
      "Testing with first layer: 16 neurons, second layer: 16 neurons\n",
      "  Epoch 0: Train Loss: 1.5444, Val Accuracy: 0.2020\n",
      "  Epoch 50: Train Loss: 1.1604, Val Accuracy: 0.5550\n",
      "  Epoch 100: Train Loss: 0.9788, Val Accuracy: 0.7180\n",
      "× Early stopping at epoch 145\n",
      "  Best validation accuracy: 0.7570\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |    Division     |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 3/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   33.42%\n",
      " LeakyReLU:   32.38%\n",
      "    Linear:   34.21%\n",
      "\n",
      "Total weight magnitude: 1.175720\n",
      "\n",
      "Testing with first layer: 24 neurons, second layer: 12 neurons\n",
      "  Epoch 0: Train Loss: 1.5102, Val Accuracy: 0.2390\n",
      "  Epoch 50: Train Loss: 1.1749, Val Accuracy: 0.4970\n",
      "  Epoch 100: Train Loss: 0.9663, Val Accuracy: 0.7280\n",
      "  Epoch 150: Train Loss: 0.7345, Val Accuracy: 0.8120\n",
      "  Epoch 200: Train Loss: 0.5767, Val Accuracy: 0.8420\n",
      "  Epoch 250: Train Loss: 0.4709, Val Accuracy: 0.8630\n",
      "× Early stopping at epoch 275\n",
      "  Best validation accuracy: 0.8650\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   34.83%\n",
      " LeakyReLU:   31.51%\n",
      "    Linear:   33.66%\n",
      "\n",
      "Total weight magnitude: 1.414057\n",
      "\n",
      "Testing with first layer: 32 neurons, second layer: 16 neurons\n",
      "  Epoch 0: Train Loss: 1.7475, Val Accuracy: 0.1800\n",
      "  Epoch 50: Train Loss: 1.0895, Val Accuracy: 0.6770\n",
      "  Epoch 100: Train Loss: 0.8647, Val Accuracy: 0.7220\n",
      "  Epoch 150: Train Loss: 0.6845, Val Accuracy: 0.7690\n",
      "  Epoch 200: Train Loss: 0.5564, Val Accuracy: 0.8400\n",
      "  Epoch 250: Train Loss: 0.4726, Val Accuracy: 0.8700\n",
      "× Early stopping at epoch 296\n",
      "  Best validation accuracy: 0.8720\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   36.78%\n",
      " LeakyReLU:   30.16%\n",
      "    Linear:   33.06%\n",
      "\n",
      "Total weight magnitude: 1.363243\n",
      "\n",
      "Testing with first layer: 16 neurons, second layer: 32 neurons\n",
      "  Epoch 0: Train Loss: 1.4532, Val Accuracy: 0.3510\n",
      "  Epoch 50: Train Loss: 1.0124, Val Accuracy: 0.7130\n",
      "  Epoch 100: Train Loss: 0.7521, Val Accuracy: 0.7670\n",
      "  Epoch 150: Train Loss: 0.5622, Val Accuracy: 0.8310\n",
      "  Epoch 200: Train Loss: 0.4542, Val Accuracy: 0.8490\n",
      "  Epoch 250: Train Loss: 0.3858, Val Accuracy: 0.8670\n",
      "  Epoch 300: Train Loss: 0.3352, Val Accuracy: 0.8830\n",
      "× Early stopping at epoch 341\n",
      "  Best validation accuracy: 0.8910\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   34.19%\n",
      " LeakyReLU:   32.48%\n",
      "    Linear:   33.33%\n",
      "\n",
      "Total weight magnitude: 1.617362\n",
      "\n",
      "Testing with first layer: 32 neurons, second layer: 32 neurons\n",
      "  Epoch 0: Train Loss: 1.6370, Val Accuracy: 0.2510\n",
      "  Epoch 50: Train Loss: 0.8981, Val Accuracy: 0.6840\n",
      "  Epoch 100: Train Loss: 0.6492, Val Accuracy: 0.7780\n",
      "  Epoch 150: Train Loss: 0.5068, Val Accuracy: 0.8360\n",
      "  Epoch 200: Train Loss: 0.4192, Val Accuracy: 0.8670\n",
      "  Epoch 250: Train Loss: 0.3566, Val Accuracy: 0.8890\n",
      "  Epoch 300: Train Loss: 0.3078, Val Accuracy: 0.8940\n",
      "  Epoch 350: Train Loss: 0.2693, Val Accuracy: 0.9050\n",
      "× Early stopping at epoch 398\n",
      "  Best validation accuracy: 0.9130\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   36.89%\n",
      " LeakyReLU:   30.20%\n",
      "    Linear:   32.91%\n",
      "\n",
      "Total weight magnitude: 1.557382\n",
      "\n",
      "Testing with first layer: 32 neurons, second layer: 64 neurons\n",
      "  Epoch 0: Train Loss: 1.7545, Val Accuracy: 0.2600\n",
      "  Epoch 50: Train Loss: 0.8202, Val Accuracy: 0.7280\n",
      "  Epoch 100: Train Loss: 0.5662, Val Accuracy: 0.8150\n",
      "  Epoch 150: Train Loss: 0.4409, Val Accuracy: 0.8630\n",
      "  Epoch 200: Train Loss: 0.3650, Val Accuracy: 0.8810\n",
      "  Epoch 250: Train Loss: 0.3124, Val Accuracy: 0.8940\n",
      "  Epoch 300: Train Loss: 0.2692, Val Accuracy: 0.9080\n",
      "× Early stopping at epoch 313\n",
      "  Best validation accuracy: 0.9080\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   36.28%\n",
      " LeakyReLU:   31.50%\n",
      "    Linear:   32.23%\n",
      "\n",
      "Total weight magnitude: 1.438728\n",
      "\n",
      "Testing with first layer: 48 neurons, second layer: 32 neurons\n",
      "  Epoch 0: Train Loss: 1.5265, Val Accuracy: 0.2140\n",
      "  Epoch 50: Train Loss: 0.8009, Val Accuracy: 0.7640\n",
      "  Epoch 100: Train Loss: 0.5484, Val Accuracy: 0.8470\n",
      "  Epoch 150: Train Loss: 0.4358, Val Accuracy: 0.8640\n",
      "  Epoch 200: Train Loss: 0.3631, Val Accuracy: 0.8830\n",
      "  Epoch 250: Train Loss: 0.3069, Val Accuracy: 0.8990\n",
      "  Epoch 300: Train Loss: 0.2646, Val Accuracy: 0.9110\n",
      "  Epoch 350: Train Loss: 0.2325, Val Accuracy: 0.9180\n",
      "× Early stopping at epoch 381\n",
      "  Best validation accuracy: 0.9220\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   35.84%\n",
      " LeakyReLU:   32.06%\n",
      "    Linear:   32.11%\n",
      "\n",
      "Total weight magnitude: 1.548067\n",
      "\n",
      "Testing with first layer: 64 neurons, second layer: 32 neurons\n",
      "  Epoch 0: Train Loss: 1.7425, Val Accuracy: 0.2120\n",
      "  Epoch 50: Train Loss: 0.8201, Val Accuracy: 0.7360\n",
      "  Epoch 100: Train Loss: 0.5566, Val Accuracy: 0.8320\n",
      "  Epoch 150: Train Loss: 0.4339, Val Accuracy: 0.8740\n",
      "  Epoch 200: Train Loss: 0.3651, Val Accuracy: 0.8890\n",
      "  Epoch 250: Train Loss: 0.3187, Val Accuracy: 0.8970\n",
      "× Early stopping at epoch 294\n",
      "  Best validation accuracy: 0.9040\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   35.86%\n",
      " LeakyReLU:   31.46%\n",
      "    Linear:   32.67%\n",
      "\n",
      "Total weight magnitude: 1.379110\n",
      "\n",
      "Testing with first layer: 24 neurons, second layer: 48 neurons\n",
      "  Epoch 0: Train Loss: 1.6765, Val Accuracy: 0.2340\n",
      "  Epoch 50: Train Loss: 0.8986, Val Accuracy: 0.6530\n",
      "  Epoch 100: Train Loss: 0.6452, Val Accuracy: 0.7740\n",
      "  Epoch 150: Train Loss: 0.4957, Val Accuracy: 0.8470\n",
      "  Epoch 200: Train Loss: 0.4117, Val Accuracy: 0.8690\n",
      "  Epoch 250: Train Loss: 0.3554, Val Accuracy: 0.8910\n",
      "  Epoch 300: Train Loss: 0.3156, Val Accuracy: 0.9040\n",
      "  Epoch 350: Train Loss: 0.2867, Val Accuracy: 0.9050\n",
      "× Early stopping at epoch 373\n",
      "  Best validation accuracy: 0.9100\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   37.84%\n",
      " LeakyReLU:   30.58%\n",
      "    Linear:   31.58%\n",
      "\n",
      "Total weight magnitude: 1.508903\n",
      "\n",
      "Testing with first layer: 20 neurons, second layer: 40 neurons\n",
      "  Epoch 0: Train Loss: 1.4007, Val Accuracy: 0.3940\n",
      "  Epoch 50: Train Loss: 0.9539, Val Accuracy: 0.6780\n",
      "  Epoch 100: Train Loss: 0.6823, Val Accuracy: 0.7870\n",
      "  Epoch 150: Train Loss: 0.5061, Val Accuracy: 0.8440\n",
      "  Epoch 200: Train Loss: 0.4111, Val Accuracy: 0.8730\n",
      "  Epoch 250: Train Loss: 0.3480, Val Accuracy: 0.8890\n",
      "× Early stopping at epoch 298\n",
      "  Best validation accuracy: 0.8940\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   35.86%\n",
      " LeakyReLU:   31.25%\n",
      "    Linear:   32.90%\n",
      "\n",
      "Total weight magnitude: 1.575033\n",
      "\n",
      "Testing with first layer: 40 neurons, second layer: 20 neurons\n",
      "  Epoch 0: Train Loss: 1.5568, Val Accuracy: 0.3060\n",
      "  Epoch 50: Train Loss: 0.9728, Val Accuracy: 0.6900\n",
      "  Epoch 100: Train Loss: 0.6798, Val Accuracy: 0.7770\n",
      "  Epoch 150: Train Loss: 0.5117, Val Accuracy: 0.8410\n",
      "  Epoch 200: Train Loss: 0.4306, Val Accuracy: 0.8650\n",
      "  Epoch 250: Train Loss: 0.3773, Val Accuracy: 0.8810\n",
      "  Epoch 300: Train Loss: 0.3348, Val Accuracy: 0.8870\n",
      "× Early stopping at epoch 306\n",
      "  Best validation accuracy: 0.8880\n",
      "\n",
      "Testing Model with Examples:\n",
      "------------------------------------------------------------\n",
      "   a     |    b     |    c     |    Predicted    |    Expected    \n",
      "------------------------------------------------------------\n",
      "   2     |    3     |    5     |    Addition     |    Addition    \n",
      "   7     |    4     |    3     |   Subtraction   |   Subtraction  \n",
      "   5     |    6     |    30    | Multiplication  | Multiplication \n",
      "   10    |    2     |    5     |    Division     |    Division    \n",
      "\n",
      "Accuracy on examples: 4/4\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   36.80%\n",
      " LeakyReLU:   30.75%\n",
      "    Linear:   32.44%\n",
      "\n",
      "Total weight magnitude: 1.459580\n",
      "\n",
      "====================================================================================================\n",
      "Configuration Results (sorted by test accuracy):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Layer 1  | Layer 2  |  Epochs  |  Val Accuracy   |  Test Accuracy  |  Success  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "   48    |    32    |   381    | 0.9220          | 0.9080          | ×\n",
      "   32    |    32    |   398    | 0.9130          | 0.9060          | ×\n",
      "   32    |    64    |   313    | 0.9080          | 0.9000          | ×\n",
      "   24    |    48    |   373    | 0.9100          | 0.9000          | ×\n",
      "   16    |    32    |   341    | 0.8910          | 0.8950          | ×\n",
      "   64    |    32    |   294    | 0.9040          | 0.8920          | ×\n",
      "   20    |    40    |   298    | 0.8940          | 0.8900          | ×\n",
      "   40    |    20    |   306    | 0.8880          | 0.8820          | ×\n",
      "   32    |    16    |   296    | 0.8720          | 0.8610          | ×\n",
      "   16    |    8     |   455    | 0.8650          | 0.8580          | ×\n",
      "   24    |    12    |   275    | 0.8650          | 0.8490          | ×\n",
      "   12    |    12    |   308    | 0.8620          | 0.8470          | ×\n",
      "   16    |    16    |   145    | 0.7570          | 0.7440          | ×\n",
      "   8     |    8     |   151    | 0.4880          | 0.5000          | ×\n",
      "\n",
      "Best Overall Configuration:\n",
      "- Layer 1: 48 neurons\n",
      "- Layer 2: 32 neurons\n",
      "- Trained for 381 epochs\n",
      "- Validation Accuracy: 0.9220\n",
      "- Test Accuracy: 0.9080\n",
      "- Success: No\n",
      "\n",
      "Final activation analysis for the best model:\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   35.84%\n",
      " LeakyReLU:   32.06%\n",
      "    Linear:   32.11%\n",
      "\n",
      "Total weight magnitude: 1.548067\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ArithmeticClassifier(nn.Module):\n",
    "    def __init__(self, first_layer_size, second_layer_size):\n",
    "        super(ArithmeticClassifier, self).__init__()\n",
    "        \n",
    "        # Input layer (3 inputs: a, b, c where c = operation(a, b))\n",
    "        self.input = nn.Linear(3, first_layer_size)\n",
    "        \n",
    "        # Triple activation for first hidden layer\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        self.identity = nn.Identity()\n",
    "        \n",
    "        # Weights for activation functions\n",
    "        self.act_weights = nn.Parameter(torch.ones(3, first_layer_size) / 3)\n",
    "        \n",
    "        # Second hidden layer (standard with ReLU)\n",
    "        self.hidden = nn.Linear(first_layer_size, second_layer_size)\n",
    "        self.hidden_activation = nn.ReLU()\n",
    "        \n",
    "        # Output layer (4 classes: add, subtract, multiply, divide)\n",
    "        self.output = nn.Linear(second_layer_size, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First hidden layer with triple activation\n",
    "        x = self.input(x)\n",
    "        \n",
    "        # Apply weighted activations\n",
    "        activated = (self.tanh(x) * self.act_weights[0].unsqueeze(0) + \n",
    "                    self.leaky_relu(x) * self.act_weights[1].unsqueeze(0) +\n",
    "                    self.identity(x) * self.act_weights[2].unsqueeze(0))\n",
    "        \n",
    "        # Second hidden layer\n",
    "        x = self.hidden(activated)\n",
    "        x = self.hidden_activation(x)\n",
    "        \n",
    "        # Output layer (no softmax here as it's included in CrossEntropyLoss)\n",
    "        return self.output(x)\n",
    "\n",
    "def analyze_activations(model):\n",
    "    # Get weights assigned to each activation function\n",
    "    with torch.no_grad():\n",
    "        weights = model.act_weights.detach().cpu()\n",
    "        \n",
    "        # Calculate importance of each activation\n",
    "        activation_names = ['Tanh', 'LeakyReLU', 'Linear']\n",
    "        importance = torch.mean(torch.abs(weights), dim=1)\n",
    "        \n",
    "        # Normalize to percentage\n",
    "        total = torch.sum(importance)\n",
    "        if total > 0:\n",
    "            importance = 100 * importance / total\n",
    "            \n",
    "            print(\"\\nActivation Function Analysis:\")\n",
    "            print(\"-\" * 40)\n",
    "            for i, name in enumerate(activation_names):\n",
    "                print(f\"{name:>10}: {importance[i].item():>7.2f}%\")\n",
    "                \n",
    "            print(f\"\\nTotal weight magnitude: {total.item():.6f}\")\n",
    "        else:\n",
    "            print(\"\\nActivation Function Analysis:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(\"All activation weights are zero\")\n",
    "\n",
    "def generate_data(num_samples=1000):\n",
    "    \"\"\"Generate training data for arithmetic operations\"\"\"\n",
    "    a = np.random.uniform(-10, 10, num_samples)\n",
    "    b = np.random.uniform(-10, 10, num_samples)\n",
    "    \n",
    "    # Avoid division by zero or very small numbers\n",
    "    b[np.abs(b) < 0.1] = 0.1 * np.sign(b[np.abs(b) < 0.1])\n",
    "    \n",
    "    # Create results for all operations\n",
    "    results = np.zeros((num_samples, 4))\n",
    "    results[:, 0] = a + b      # Addition\n",
    "    results[:, 1] = a - b      # Subtraction\n",
    "    results[:, 2] = a * b      # Multiplication\n",
    "    results[:, 3] = a / b      # Division\n",
    "    \n",
    "    # For each sample, select one operation randomly\n",
    "    selected_ops = np.random.randint(0, 4, num_samples)\n",
    "    c = np.zeros(num_samples)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        c[i] = results[i, selected_ops[i]]\n",
    "    \n",
    "    # Create input features [a, b, c] and labels [operation]\n",
    "    X = np.column_stack((a, b, c))\n",
    "    y = selected_ops\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def train_and_evaluate(first_layer_size, second_layer_size, max_epochs=500):\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create model\n",
    "    model = ArithmeticClassifier(first_layer_size, second_layer_size)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Generate data\n",
    "    X_train, y_train = generate_data(5000)\n",
    "    X_val, y_val = generate_data(1000)\n",
    "    X_test, y_test = generate_data(1000)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.LongTensor(y_val)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_model_state = None\n",
    "    patience = 20\n",
    "    no_improve = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(max_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            val_accuracy = (predicted == y_val_tensor).sum().item() / y_val_tensor.size(0)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            \n",
    "            # Print progress occasionally\n",
    "            if epoch % 50 == 0:\n",
    "                print(f\"  Epoch {epoch}: Train Loss: {loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "            \n",
    "            # Track best model\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "            \n",
    "            # Check if we've reached target accuracy\n",
    "            if val_accuracy >= 0.99:\n",
    "                print(f\"✓ Target achieved with layers ({first_layer_size}, {second_layer_size}) at epoch {epoch+1}\")\n",
    "                print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "                \n",
    "                # Load best model\n",
    "                if best_model_state:\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                \n",
    "                # Final test evaluation\n",
    "                test_outputs = model(X_test_tensor)\n",
    "                _, predicted = torch.max(test_outputs, 1)\n",
    "                test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "                \n",
    "                return {\n",
    "                    'model': model,\n",
    "                    'layer1': first_layer_size,\n",
    "                    'layer2': second_layer_size,\n",
    "                    'epochs': epoch+1,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'test_accuracy': test_accuracy,\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_accuracies': val_accuracies,\n",
    "                    'success': True\n",
    "                }\n",
    "            \n",
    "            # Early stopping\n",
    "            if no_improve >= patience:\n",
    "                print(f\"× Early stopping at epoch {epoch+1}\")\n",
    "                print(f\"  Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "                \n",
    "                # Load best model\n",
    "                if best_model_state:\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                \n",
    "                # Final test evaluation\n",
    "                test_outputs = model(X_test_tensor)\n",
    "                _, predicted = torch.max(test_outputs, 1)\n",
    "                test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "                \n",
    "                return {\n",
    "                    'model': model,\n",
    "                    'layer1': first_layer_size,\n",
    "                    'layer2': second_layer_size,\n",
    "                    'epochs': epoch+1,\n",
    "                    'val_accuracy': best_val_accuracy,\n",
    "                    'test_accuracy': test_accuracy,\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_accuracies': val_accuracies,\n",
    "                    'success': best_val_accuracy >= 0.99\n",
    "                }\n",
    "    \n",
    "    # Load best model before final evaluation\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Final test evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(test_outputs, 1)\n",
    "        test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "    \n",
    "    print(f\"× Reached max epochs ({max_epochs})\")\n",
    "    print(f\"  Best validation accuracy: {best_val_accuracy:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'layer1': first_layer_size,\n",
    "        'layer2': second_layer_size,\n",
    "        'epochs': max_epochs,\n",
    "        'val_accuracy': best_val_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_losses': train_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'success': best_val_accuracy >= 0.99\n",
    "    }\n",
    "\n",
    "def test_examples(model):\n",
    "    \"\"\"Test model on specific examples with all four operations\"\"\"\n",
    "    operations = ['Addition', 'Subtraction', 'Multiplication', 'Division']\n",
    "    \n",
    "    examples = [\n",
    "        [2, 3, 5],      # 2 + 3 = 5\n",
    "        [7, 4, 3],      # 7 - 4 = 3\n",
    "        [5, 6, 30],     # 5 * 6 = 30\n",
    "        [10, 2, 5],     # 10 / 2 = 5\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting Model with Examples:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'a':^8} | {'b':^8} | {'c':^8} | {'Predicted':^15} | {'Expected':^15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, example in enumerate(examples):\n",
    "            a, b, c = example\n",
    "            input_tensor = torch.FloatTensor([example])\n",
    "            output = model(input_tensor)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            pred_op = operations[predicted.item()]\n",
    "            expected_op = operations[i]\n",
    "            \n",
    "            print(f\"{a:^8} | {b:^8} | {c:^8} | {pred_op:^15} | {expected_op:^15}\")\n",
    "            \n",
    "            if pred_op == expected_op:\n",
    "                correct += 1\n",
    "    \n",
    "    print(f\"\\nAccuracy on examples: {correct}/{len(examples)}\")\n",
    "\n",
    "# Test different combinations of layer sizes\n",
    "print(\"Testing different layer size combinations for arithmetic operations classifier\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define combinations to test\n",
    "layer_combinations = [\n",
    "    (8, 8),\n",
    "    (16, 8),\n",
    "    (12, 12),\n",
    "    (16, 16),\n",
    "    (24, 12),\n",
    "    (32, 16),\n",
    "    (16, 32)\n",
    "]\n",
    "\n",
    "additional_combinations = [\n",
    "    (32, 32),    # Balanced larger model\n",
    "    (32, 64),    # Wider second layer\n",
    "    (48, 32),    # Wider first layer\n",
    "    (64, 32),    # Even wider first layer \n",
    "    (24, 48),    # Another asymmetric configuration\n",
    "    (20, 40),    # Smaller but similar ratio to the best so far\n",
    "    (40, 20)     # Reverse ratio experiment\n",
    "]\n",
    "\n",
    "layer_combinations.extend(additional_combinations)\n",
    "\n",
    "results = []\n",
    "\n",
    "for layer1, layer2 in layer_combinations:\n",
    "    print(f\"\\nTesting with first layer: {layer1} neurons, second layer: {layer2} neurons\")\n",
    "    result = train_and_evaluate(layer1, layer2)\n",
    "    \n",
    "    test_examples(result['model'])\n",
    "    analyze_activations(result['model'])\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    # If we've found a successful model, we can stop\n",
    "    if result['success'] and result['test_accuracy'] >= 0.99:\n",
    "        print(f\"\\n✓ Found minimum configuration with layers ({layer1}, {layer2})\")\n",
    "        break\n",
    "\n",
    "# Show summary of all configurations\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Configuration Results (sorted by test accuracy):\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'Layer 1':^8} | {'Layer 2':^8} | {'Epochs':^8} | {'Val Accuracy':^15} | {'Test Accuracy':^15} | {'Success':^10}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Sort by test accuracy (best first)\n",
    "for r in sorted(results, key=lambda x: x['test_accuracy'], reverse=True):\n",
    "    print(f\"{r['layer1']:^8} | {r['layer2']:^8} | {r['epochs']:^8} | {r['val_accuracy']:.4f}{' ':^9} | {r['test_accuracy']:.4f}{' ':^9} | {'✓' if r['success'] else '×'}\")\n",
    "\n",
    "# Find the best configuration\n",
    "best_config = max(results, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "print(\"\\nBest Overall Configuration:\")\n",
    "print(f\"- Layer 1: {best_config['layer1']} neurons\")\n",
    "print(f\"- Layer 2: {best_config['layer2']} neurons\")\n",
    "print(f\"- Trained for {best_config['epochs']} epochs\")\n",
    "print(f\"- Validation Accuracy: {best_config['val_accuracy']:.4f}\")\n",
    "print(f\"- Test Accuracy: {best_config['test_accuracy']:.4f}\")\n",
    "print(f\"- Success: {'Yes' if best_config['success'] else 'No'}\")\n",
    "\n",
    "# Final activation analysis\n",
    "print(\"\\nFinal activation analysis for the best model:\")\n",
    "analyze_activations(best_config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fe214e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the best configuration for visualization\n",
      "======================================================================\n",
      "  Epoch 0: Train Loss: 1.4374, Val Accuracy: 0.2720\n",
      "  Epoch 50: Train Loss: 0.8009, Val Accuracy: 0.7520\n",
      "  Epoch 100: Train Loss: 0.4971, Val Accuracy: 0.8490\n",
      "  Epoch 150: Train Loss: 0.3570, Val Accuracy: 0.8740\n",
      "  Epoch 200: Train Loss: 0.2666, Val Accuracy: 0.8930\n",
      "  Epoch 250: Train Loss: 0.2099, Val Accuracy: 0.9180\n",
      "  Epoch 300: Train Loss: 0.1729, Val Accuracy: 0.9420\n",
      "  Epoch 350: Train Loss: 0.1477, Val Accuracy: 0.9520\n",
      "  Epoch 400: Train Loss: 0.1287, Val Accuracy: 0.9550\n",
      "  Epoch 450: Train Loss: 0.1130, Val Accuracy: 0.9580\n",
      "  Epoch 500: Train Loss: 0.0997, Val Accuracy: 0.9610\n",
      "  Epoch 550: Train Loss: 0.0893, Val Accuracy: 0.9680\n",
      "  Epoch 600: Train Loss: 0.0810, Val Accuracy: 0.9690\n",
      "  Epoch 650: Train Loss: 0.0740, Val Accuracy: 0.9730\n",
      "  Epoch 700: Train Loss: 0.0674, Val Accuracy: 0.9730\n",
      "  Epoch 750: Train Loss: 0.0614, Val Accuracy: 0.9760\n",
      "  Epoch 800: Train Loss: 0.0561, Val Accuracy: 0.9760\n",
      "× Early stopping at epoch 808\n",
      "  Best validation accuracy: 0.9790\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   34.73%\n",
      " LeakyReLU:   32.28%\n",
      "    Linear:   32.99%\n",
      "\n",
      "Total weight magnitude: 1.518473\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "Configuration Results:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layer 1  | Layer 2  | Layer 3  |  Epochs  |  Val Accuracy   |  Test Accuracy  |  Success  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  128    |    64    |    32    |   808    | 0.9790          | 0.9790          | ×\n",
      "\n",
      "Best Configuration:\n",
      "- Layer 1: 128 neurons\n",
      "- Layer 2: 64 neurons\n",
      "- Layer 3: 32 neurons\n",
      "- Trained for 808 epochs\n",
      "- Validation Accuracy: 0.9790\n",
      "- Test Accuracy: 0.9790\n",
      "- Success: No\n",
      "\n",
      "Activation function analysis:\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   34.73%\n",
      " LeakyReLU:   32.28%\n",
      "    Linear:   32.99%\n",
      "\n",
      "Total weight magnitude: 1.518473\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class ArithmeticClassifier(nn.Module):\n",
    "   def __init__(self, first_layer_size, second_layer_size, third_layer_size):\n",
    "       super(ArithmeticClassifier, self).__init__()\n",
    "       \n",
    "       # Input layer (3 inputs: a, b, c where c = operation(a, b))\n",
    "       self.input = nn.Linear(3, first_layer_size)\n",
    "       \n",
    "       # Triple activation for first hidden layer\n",
    "       self.tanh = nn.Tanh()\n",
    "       self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "       self.identity = nn.Identity()\n",
    "       \n",
    "       # Weights for activation functions\n",
    "       self.act_weights = nn.Parameter(torch.ones(3, first_layer_size) / 3)\n",
    "       \n",
    "       # Second hidden layer\n",
    "       self.hidden = nn.Linear(first_layer_size, second_layer_size)\n",
    "       self.hidden_activation = nn.ReLU()\n",
    "       \n",
    "       # Third hidden layer\n",
    "       self.hidden2 = nn.Linear(second_layer_size, third_layer_size)\n",
    "       self.hidden_activation2 = nn.ReLU()\n",
    "       \n",
    "       # Output layer (4 classes: add, subtract, multiply, divide)\n",
    "       self.output = nn.Linear(third_layer_size, 4)\n",
    "       \n",
    "   def forward(self, x):\n",
    "       # First hidden layer with triple activation\n",
    "       x = self.input(x)\n",
    "       \n",
    "       # Apply weighted activations\n",
    "       activated = (self.tanh(x) * self.act_weights[0].unsqueeze(0) + \n",
    "                   self.leaky_relu(x) * self.act_weights[1].unsqueeze(0) +\n",
    "                   self.identity(x) * self.act_weights[2].unsqueeze(0))\n",
    "       \n",
    "       # Second hidden layer\n",
    "       x = self.hidden(activated)\n",
    "       x = self.hidden_activation(x)\n",
    "       \n",
    "       # Third hidden layer\n",
    "       x = self.hidden2(x)\n",
    "       x = self.hidden_activation2(x)\n",
    "       \n",
    "       # Output layer\n",
    "       return self.output(x)\n",
    "\n",
    "def analyze_activations(model):\n",
    "   # Get weights assigned to each activation function\n",
    "   with torch.no_grad():\n",
    "       weights = model.act_weights.detach().cpu()\n",
    "       \n",
    "       # Calculate importance of each activation\n",
    "       activation_names = ['Tanh', 'LeakyReLU', 'Linear']\n",
    "       importance = torch.mean(torch.abs(weights), dim=1)\n",
    "       \n",
    "       # Normalize to percentage\n",
    "       total = torch.sum(importance)\n",
    "       if total > 0:\n",
    "           importance = 100 * importance / total\n",
    "           \n",
    "           print(\"\\nActivation Function Analysis:\")\n",
    "           print(\"-\" * 40)\n",
    "           for i, name in enumerate(activation_names):\n",
    "               print(f\"{name:>10}: {importance[i].item():>7.2f}%\")\n",
    "               \n",
    "           print(f\"\\nTotal weight magnitude: {total.item():.6f}\")\n",
    "       else:\n",
    "           print(\"\\nActivation Function Analysis:\")\n",
    "           print(\"-\" * 40)\n",
    "           print(\"All activation weights are zero\")\n",
    "\n",
    "def generate_data(num_samples=1000):\n",
    "   \"\"\"Generate training data for arithmetic operations\"\"\"\n",
    "   a = np.random.uniform(-10, 10, num_samples)\n",
    "   b = np.random.uniform(-10, 10, num_samples)\n",
    "   \n",
    "   # Increase minimum threshold for b values\n",
    "   b[np.abs(b) < 0.5] = 0.5 * np.sign(b[np.abs(b) < 0.5])\n",
    "   \n",
    "   # Round values to reduce floating point issues\n",
    "   a = np.round(a, 2)\n",
    "   b = np.round(b, 2)\n",
    "   \n",
    "   # Create results for all operations\n",
    "   results = np.zeros((num_samples, 4))\n",
    "   results[:, 0] = a + b      # Addition\n",
    "   results[:, 1] = a - b      # Subtraction\n",
    "   results[:, 2] = a * b      # Multiplication\n",
    "   results[:, 3] = a / b      # Division\n",
    "   \n",
    "   # For each sample, select one operation randomly\n",
    "   selected_ops = np.random.randint(0, 4, num_samples)\n",
    "   c = np.zeros(num_samples)\n",
    "   \n",
    "   for i in range(num_samples):\n",
    "       c[i] = results[i, selected_ops[i]]\n",
    "   \n",
    "   # Create input features [a, b, c] and labels [operation]\n",
    "   X = np.column_stack((a, b, c))\n",
    "   y = selected_ops\n",
    "   \n",
    "   return X, y\n",
    "\n",
    "def train_and_evaluate(first_layer_size, second_layer_size, third_layer_size, max_epochs=1000):\n",
    "   torch.manual_seed(42)\n",
    "   np.random.seed(42)\n",
    "   \n",
    "   # Create model\n",
    "   model = ArithmeticClassifier(first_layer_size, second_layer_size, third_layer_size)\n",
    "   optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "   criterion = nn.CrossEntropyLoss()\n",
    "   \n",
    "   # Generate data\n",
    "   X_train, y_train = generate_data(5000)\n",
    "   X_val, y_val = generate_data(1000)\n",
    "   X_test, y_test = generate_data(1000)\n",
    "   \n",
    "   # Convert to tensors\n",
    "   X_train_tensor = torch.FloatTensor(X_train)\n",
    "   y_train_tensor = torch.LongTensor(y_train)\n",
    "   X_val_tensor = torch.FloatTensor(X_val)\n",
    "   y_val_tensor = torch.LongTensor(y_val)\n",
    "   X_test_tensor = torch.FloatTensor(X_test)\n",
    "   y_test_tensor = torch.LongTensor(y_test)\n",
    "   \n",
    "   best_val_accuracy = 0\n",
    "   best_model_state = None\n",
    "   patience = 50\n",
    "   no_improve = 0\n",
    "   \n",
    "   train_losses = []\n",
    "   val_accuracies = []\n",
    "   \n",
    "   # Training loop\n",
    "   for epoch in range(max_epochs):\n",
    "       # Train\n",
    "       model.train()\n",
    "       optimizer.zero_grad()\n",
    "       outputs = model(X_train_tensor)\n",
    "       loss = criterion(outputs, y_train_tensor)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       \n",
    "       train_losses.append(loss.item())\n",
    "       \n",
    "       # Evaluate\n",
    "       model.eval()\n",
    "       with torch.no_grad():\n",
    "           val_outputs = model(X_val_tensor)\n",
    "           _, predicted = torch.max(val_outputs, 1)\n",
    "           val_accuracy = (predicted == y_val_tensor).sum().item() / y_val_tensor.size(0)\n",
    "           val_accuracies.append(val_accuracy)\n",
    "           \n",
    "           # Print progress occasionally\n",
    "           if epoch % 50 == 0:\n",
    "               print(f\"  Epoch {epoch}: Train Loss: {loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "           \n",
    "           # Track best model\n",
    "           if val_accuracy > best_val_accuracy:\n",
    "               best_val_accuracy = val_accuracy\n",
    "               best_model_state = model.state_dict().copy()\n",
    "               no_improve = 0\n",
    "           else:\n",
    "               no_improve += 1\n",
    "           \n",
    "           # Check if we've reached target accuracy\n",
    "           if val_accuracy >= 0.999:\n",
    "               print(f\"✓ Target achieved with layers ({first_layer_size}, {second_layer_size}, {third_layer_size}) at epoch {epoch+1}\")\n",
    "               print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "               \n",
    "               # Load best model\n",
    "               if best_model_state:\n",
    "                   model.load_state_dict(best_model_state)\n",
    "               \n",
    "               # Final test evaluation\n",
    "               test_outputs = model(X_test_tensor)\n",
    "               _, predicted = torch.max(test_outputs, 1)\n",
    "               test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "               \n",
    "               return {\n",
    "                   'model': model,\n",
    "                   'layer1': first_layer_size,\n",
    "                   'layer2': second_layer_size,\n",
    "                   'layer3': third_layer_size,\n",
    "                   'epochs': epoch+1,\n",
    "                   'val_accuracy': val_accuracy,\n",
    "                   'test_accuracy': test_accuracy,\n",
    "                   'train_losses': train_losses,\n",
    "                   'val_accuracies': val_accuracies,\n",
    "                   'success': True,\n",
    "                   'X_test': X_test,\n",
    "                   'y_test': y_test,\n",
    "                   'y_pred': predicted.cpu().numpy()\n",
    "               }\n",
    "           \n",
    "           # Early stopping\n",
    "           if no_improve >= patience:\n",
    "               print(f\"× Early stopping at epoch {epoch+1}\")\n",
    "               print(f\"  Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "               \n",
    "               # Load best model\n",
    "               if best_model_state:\n",
    "                   model.load_state_dict(best_model_state)\n",
    "               \n",
    "               # Final test evaluation\n",
    "               test_outputs = model(X_test_tensor)\n",
    "               _, predicted = torch.max(test_outputs, 1)\n",
    "               test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "               \n",
    "               return {\n",
    "                   'model': model,\n",
    "                   'layer1': first_layer_size,\n",
    "                   'layer2': second_layer_size,\n",
    "                   'layer3': third_layer_size,\n",
    "                   'epochs': epoch+1,\n",
    "                   'val_accuracy': best_val_accuracy,\n",
    "                   'test_accuracy': test_accuracy,\n",
    "                   'train_losses': train_losses,\n",
    "                   'val_accuracies': val_accuracies,\n",
    "                   'success': best_val_accuracy >= 0.999,\n",
    "                   'X_test': X_test,\n",
    "                   'y_test': y_test,\n",
    "                   'y_pred': predicted.cpu().numpy()\n",
    "               }\n",
    "   \n",
    "   # Load best model before final evaluation\n",
    "   if best_model_state:\n",
    "       model.load_state_dict(best_model_state)\n",
    "   \n",
    "   # Final test evaluation\n",
    "   model.eval()\n",
    "   with torch.no_grad():\n",
    "       test_outputs = model(X_test_tensor)\n",
    "       _, predicted = torch.max(test_outputs, 1)\n",
    "       test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "   \n",
    "   print(f\"× Reached max epochs ({max_epochs})\")\n",
    "   print(f\"  Best validation accuracy: {best_val_accuracy:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
    "   \n",
    "   return {\n",
    "       'model': model,\n",
    "       'layer1': first_layer_size,\n",
    "       'layer2': second_layer_size,\n",
    "       'layer3': third_layer_size,\n",
    "       'epochs': max_epochs,\n",
    "       'val_accuracy': best_val_accuracy,\n",
    "       'test_accuracy': test_accuracy,\n",
    "       'train_losses': train_losses,\n",
    "       'val_accuracies': val_accuracies,\n",
    "       'success': best_val_accuracy >= 0.999,\n",
    "       'X_test': X_test,\n",
    "       'y_test': y_test,\n",
    "       'y_pred': predicted.cpu().numpy()\n",
    "   }\n",
    "\n",
    "def plot_confusion_matrix(result):\n",
    "   \"\"\"Plot confusion matrix for the test results\"\"\"\n",
    "   operations = ['Addition', 'Subtraction', 'Multiplication', 'Division']\n",
    "   \n",
    "   # Calculate confusion matrix\n",
    "   cm = confusion_matrix(result['y_test'], result['y_pred'])\n",
    "   \n",
    "   # Plot\n",
    "   plt.figure(figsize=(10, 8))\n",
    "   sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=operations, yticklabels=operations)\n",
    "   plt.ylabel('True Label')\n",
    "   plt.xlabel('Predicted Label')\n",
    "   plt.title('Confusion Matrix')\n",
    "   plt.show()\n",
    "\n",
    "# Test the best configuration from previous run\n",
    "print(\"Training the best configuration for visualization\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Best configuration\n",
    "layer1 = 128\n",
    "layer2 = 64 \n",
    "layer3 = 32\n",
    "\n",
    "result = train_and_evaluate(layer1, layer2, layer3)\n",
    "analyze_activations(result['model'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(result)\n",
    "\n",
    "# Show summary\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"Configuration Results:\")\n",
    "print(\"-\" * 120)\n",
    "print(f\"{'Layer 1':^8} | {'Layer 2':^8} | {'Layer 3':^8} | {'Epochs':^8} | {'Val Accuracy':^15} | {'Test Accuracy':^15} | {'Success':^10}\")\n",
    "print(\"-\" * 120)\n",
    "print(f\"{result['layer1']:^8} | {result['layer2']:^8} | {result['layer3']:^8} | {result['epochs']:^8} | {result['val_accuracy']:.4f}{' ':^9} | {result['test_accuracy']:.4f}{' ':^9} | {'✓' if result['success'] else '×'}\")\n",
    "\n",
    "print(\"\\nBest Configuration:\")\n",
    "print(f\"- Layer 1: {result['layer1']} neurons\")\n",
    "print(f\"- Layer 2: {result['layer2']} neurons\")\n",
    "print(f\"- Layer 3: {result['layer3']} neurons\")\n",
    "print(f\"- Trained for {result['epochs']} epochs\")\n",
    "print(f\"- Validation Accuracy: {result['val_accuracy']:.4f}\")\n",
    "print(f\"- Test Accuracy: {result['test_accuracy']:.4f}\")\n",
    "print(f\"- Success: {'Yes' if result['success'] else 'No'}\")\n",
    "\n",
    "print(\"\\nActivation function analysis:\")\n",
    "analyze_activations(result['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7eb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the best configuration for visualization\n",
      "======================================================================\n",
      "  Epoch 0: Train Loss: 1.4374, Val Accuracy: 0.2720\n",
      "  Epoch 50: Train Loss: 0.8009, Val Accuracy: 0.7520\n",
      "  Epoch 100: Train Loss: 0.4971, Val Accuracy: 0.8490\n",
      "  Epoch 150: Train Loss: 0.3570, Val Accuracy: 0.8740\n",
      "  Epoch 200: Train Loss: 0.2666, Val Accuracy: 0.8930\n",
      "  Epoch 250: Train Loss: 0.2099, Val Accuracy: 0.9180\n",
      "  Epoch 300: Train Loss: 0.1729, Val Accuracy: 0.9420\n",
      "  Epoch 350: Train Loss: 0.1477, Val Accuracy: 0.9520\n",
      "  Epoch 400: Train Loss: 0.1287, Val Accuracy: 0.9550\n",
      "  Epoch 450: Train Loss: 0.1130, Val Accuracy: 0.9580\n",
      "  Epoch 500: Train Loss: 0.0997, Val Accuracy: 0.9610\n",
      "  Epoch 550: Train Loss: 0.0893, Val Accuracy: 0.9680\n",
      "  Epoch 600: Train Loss: 0.0810, Val Accuracy: 0.9690\n",
      "  Epoch 650: Train Loss: 0.0740, Val Accuracy: 0.9730\n",
      "  Epoch 700: Train Loss: 0.0674, Val Accuracy: 0.9730\n",
      "  Epoch 750: Train Loss: 0.0614, Val Accuracy: 0.9760\n",
      "  Epoch 800: Train Loss: 0.0561, Val Accuracy: 0.9760\n",
      "× Early stopping at epoch 808\n",
      "  Best validation accuracy: 0.9790\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   34.73%\n",
      " LeakyReLU:   32.28%\n",
      "    Linear:   32.99%\n",
      "\n",
      "Total weight magnitude: 1.518473\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "Configuration Results:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layer 1  | Layer 2  | Layer 3  |  Epochs  |  Val Accuracy   |  Test Accuracy  |  Success  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  128    |    64    |    32    |   808    | 0.9790          | 0.9790          | ×\n",
      "\n",
      "Best Configuration:\n",
      "- Layer 1: 128 neurons\n",
      "- Layer 2: 64 neurons\n",
      "- Layer 3: 32 neurons\n",
      "- Trained for 808 epochs\n",
      "- Validation Accuracy: 0.9790\n",
      "- Test Accuracy: 0.9790\n",
      "- Success: No\n",
      "\n",
      "Activation function analysis:\n",
      "\n",
      "Activation Function Analysis:\n",
      "----------------------------------------\n",
      "      Tanh:   34.73%\n",
      " LeakyReLU:   32.28%\n",
      "    Linear:   32.99%\n",
      "\n",
      "Total weight magnitude: 1.518473\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class ArithmeticClassifier(nn.Module):\n",
    "   def __init__(self, first_layer_size, second_layer_size, third_layer_size):\n",
    "       super(ArithmeticClassifier, self).__init__()\n",
    "       \n",
    "       # Input layer (3 inputs: a, b, c where c = operation(a, b))\n",
    "       self.input = nn.Linear(3, first_layer_size)\n",
    "       \n",
    "       # Triple activation for first hidden layer\n",
    "       self.tanh = nn.Tanh()\n",
    "       self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "       self.identity = nn.Identity()\n",
    "       \n",
    "       # Weights for activation functions\n",
    "       self.act_weights = nn.Parameter(torch.ones(3, first_layer_size) / 3)\n",
    "       \n",
    "       # Second hidden layer\n",
    "       self.hidden = nn.Linear(first_layer_size, second_layer_size)\n",
    "       self.hidden_activation = nn.ReLU()\n",
    "       \n",
    "       # Third hidden layer\n",
    "       self.hidden2 = nn.Linear(second_layer_size, third_layer_size)\n",
    "       self.hidden_activation2 = nn.ReLU()\n",
    "       \n",
    "       # Output layer (4 classes: add, subtract, multiply, divide)\n",
    "       self.output = nn.Linear(third_layer_size, 4)\n",
    "       \n",
    "   def forward(self, x):\n",
    "       # First hidden layer with triple activation\n",
    "       x = self.input(x)\n",
    "       \n",
    "       # Apply weighted activations\n",
    "       activated = (self.tanh(x) * self.act_weights[0].unsqueeze(0) + \n",
    "                   self.leaky_relu(x) * self.act_weights[1].unsqueeze(0) +\n",
    "                   self.identity(x) * self.act_weights[2].unsqueeze(0))\n",
    "       \n",
    "       # Second hidden layer\n",
    "       x = self.hidden(activated)\n",
    "       x = self.hidden_activation(x)\n",
    "       \n",
    "       # Third hidden layer\n",
    "       x = self.hidden2(x)\n",
    "       x = self.hidden_activation2(x)\n",
    "       \n",
    "       # Output layer\n",
    "       return self.output(x)\n",
    "\n",
    "def analyze_activations(model):\n",
    "   # Get weights assigned to each activation function\n",
    "   with torch.no_grad():\n",
    "       weights = model.act_weights.detach().cpu()\n",
    "       \n",
    "       # Calculate importance of each activation\n",
    "       activation_names = ['Tanh', 'LeakyReLU', 'Linear']\n",
    "       importance = torch.mean(torch.abs(weights), dim=1)\n",
    "       \n",
    "       # Normalize to percentage\n",
    "       total = torch.sum(importance)\n",
    "       if total > 0:\n",
    "           importance = 100 * importance / total\n",
    "           \n",
    "           print(\"\\nActivation Function Analysis:\")\n",
    "           print(\"-\" * 40)\n",
    "           for i, name in enumerate(activation_names):\n",
    "               print(f\"{name:>10}: {importance[i].item():>7.2f}%\")\n",
    "               \n",
    "           print(f\"\\nTotal weight magnitude: {total.item():.6f}\")\n",
    "       else:\n",
    "           print(\"\\nActivation Function Analysis:\")\n",
    "           print(\"-\" * 40)\n",
    "           print(\"All activation weights are zero\")\n",
    "\n",
    "def generate_data(num_samples=1000):\n",
    "   \"\"\"Generate training data for arithmetic operations\"\"\"\n",
    "   a = np.random.uniform(-10, 10, num_samples)\n",
    "   b = np.random.uniform(-10, 10, num_samples)\n",
    "   \n",
    "   # Increase minimum threshold for b values\n",
    "   b[np.abs(b) < 0.5] = 0.5 * np.sign(b[np.abs(b) < 0.5])\n",
    "   \n",
    "   # Round values to reduce floating point issues\n",
    "   a = np.round(a, 2)\n",
    "   b = np.round(b, 2)\n",
    "   \n",
    "   # Create results for all operations\n",
    "   results = np.zeros((num_samples, 4))\n",
    "   results[:, 0] = a + b      # Addition\n",
    "   results[:, 1] = a - b      # Subtraction\n",
    "   results[:, 2] = a * b      # Multiplication\n",
    "   results[:, 3] = a / b      # Division\n",
    "   \n",
    "   # For each sample, select one operation randomly\n",
    "   selected_ops = np.random.randint(0, 4, num_samples)\n",
    "   c = np.zeros(num_samples)\n",
    "   \n",
    "   for i in range(num_samples):\n",
    "       c[i] = results[i, selected_ops[i]]\n",
    "   \n",
    "   # Create input features [a, b, c] and labels [operation]\n",
    "   X = np.column_stack((a, b, c))\n",
    "   y = selected_ops\n",
    "   \n",
    "   return X, y\n",
    "\n",
    "def train_and_evaluate(first_layer_size, second_layer_size, third_layer_size, max_epochs=1000):\n",
    "   torch.manual_seed(42)\n",
    "   np.random.seed(42)\n",
    "   \n",
    "   # Create model\n",
    "   model = ArithmeticClassifier(first_layer_size, second_layer_size, third_layer_size)\n",
    "   optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "   criterion = nn.CrossEntropyLoss()\n",
    "   \n",
    "   # Generate data\n",
    "   X_train, y_train = generate_data(5000)\n",
    "   X_val, y_val = generate_data(1000)\n",
    "   X_test, y_test = generate_data(1000)\n",
    "   \n",
    "   # Convert to tensors\n",
    "   X_train_tensor = torch.FloatTensor(X_train)\n",
    "   y_train_tensor = torch.LongTensor(y_train)\n",
    "   X_val_tensor = torch.FloatTensor(X_val)\n",
    "   y_val_tensor = torch.LongTensor(y_val)\n",
    "   X_test_tensor = torch.FloatTensor(X_test)\n",
    "   y_test_tensor = torch.LongTensor(y_test)\n",
    "   \n",
    "   best_val_accuracy = 0\n",
    "   best_model_state = None\n",
    "   patience = 50\n",
    "   no_improve = 0\n",
    "   \n",
    "   train_losses = []\n",
    "   val_accuracies = []\n",
    "   \n",
    "   # Training loop\n",
    "   for epoch in range(max_epochs):\n",
    "       # Train\n",
    "       model.train()\n",
    "       optimizer.zero_grad()\n",
    "       outputs = model(X_train_tensor)\n",
    "       loss = criterion(outputs, y_train_tensor)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       \n",
    "       train_losses.append(loss.item())\n",
    "       \n",
    "       # Evaluate\n",
    "       model.eval()\n",
    "       with torch.no_grad():\n",
    "           val_outputs = model(X_val_tensor)\n",
    "           _, predicted = torch.max(val_outputs, 1)\n",
    "           val_accuracy = (predicted == y_val_tensor).sum().item() / y_val_tensor.size(0)\n",
    "           val_accuracies.append(val_accuracy)\n",
    "           \n",
    "           # Print progress occasionally\n",
    "           if epoch % 50 == 0:\n",
    "               print(f\"  Epoch {epoch}: Train Loss: {loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "           \n",
    "           # Track best model\n",
    "           if val_accuracy > best_val_accuracy:\n",
    "               best_val_accuracy = val_accuracy\n",
    "               best_model_state = model.state_dict().copy()\n",
    "               no_improve = 0\n",
    "           else:\n",
    "               no_improve += 1\n",
    "           \n",
    "           # Check if we've reached target accuracy\n",
    "           if val_accuracy >= 0.999:\n",
    "               print(f\"✓ Target achieved with layers ({first_layer_size}, {second_layer_size}, {third_layer_size}) at epoch {epoch+1}\")\n",
    "               print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "               \n",
    "               # Load best model\n",
    "               if best_model_state:\n",
    "                   model.load_state_dict(best_model_state)\n",
    "               \n",
    "               # Final test evaluation\n",
    "               test_outputs = model(X_test_tensor)\n",
    "               _, predicted = torch.max(test_outputs, 1)\n",
    "               test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "               \n",
    "               return {\n",
    "                   'model': model,\n",
    "                   'layer1': first_layer_size,\n",
    "                   'layer2': second_layer_size,\n",
    "                   'layer3': third_layer_size,\n",
    "                   'epochs': epoch+1,\n",
    "                   'val_accuracy': val_accuracy,\n",
    "                   'test_accuracy': test_accuracy,\n",
    "                   'train_losses': train_losses,\n",
    "                   'val_accuracies': val_accuracies,\n",
    "                   'success': True,\n",
    "                   'X_test': X_test,\n",
    "                   'y_test': y_test,\n",
    "                   'y_pred': predicted.cpu().numpy()\n",
    "               }\n",
    "           \n",
    "           # Early stopping\n",
    "           if no_improve >= patience:\n",
    "               print(f\"× Early stopping at epoch {epoch+1}\")\n",
    "               print(f\"  Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "               \n",
    "               # Load best model\n",
    "               if best_model_state:\n",
    "                   model.load_state_dict(best_model_state)\n",
    "               \n",
    "               # Final test evaluation\n",
    "               test_outputs = model(X_test_tensor)\n",
    "               _, predicted = torch.max(test_outputs, 1)\n",
    "               test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "               \n",
    "               return {\n",
    "                   'model': model,\n",
    "                   'layer1': first_layer_size,\n",
    "                   'layer2': second_layer_size,\n",
    "                   'layer3': third_layer_size,\n",
    "                   'epochs': epoch+1,\n",
    "                   'val_accuracy': best_val_accuracy,\n",
    "                   'test_accuracy': test_accuracy,\n",
    "                   'train_losses': train_losses,\n",
    "                   'val_accuracies': val_accuracies,\n",
    "                   'success': best_val_accuracy >= 0.999,\n",
    "                   'X_test': X_test,\n",
    "                   'y_test': y_test,\n",
    "                   'y_pred': predicted.cpu().numpy()\n",
    "               }\n",
    "   \n",
    "   # Load best model before final evaluation\n",
    "   if best_model_state:\n",
    "       model.load_state_dict(best_model_state)\n",
    "   \n",
    "   # Final test evaluation\n",
    "   model.eval()\n",
    "   with torch.no_grad():\n",
    "       test_outputs = model(X_test_tensor)\n",
    "       _, predicted = torch.max(test_outputs, 1)\n",
    "       test_accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "   \n",
    "   print(f\"× Reached max epochs ({max_epochs})\")\n",
    "   print(f\"  Best validation accuracy: {best_val_accuracy:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
    "   \n",
    "   return {\n",
    "       'model': model,\n",
    "       'layer1': first_layer_size,\n",
    "       'layer2': second_layer_size,\n",
    "       'layer3': third_layer_size,\n",
    "       'epochs': max_epochs,\n",
    "       'val_accuracy': best_val_accuracy,\n",
    "       'test_accuracy': test_accuracy,\n",
    "       'train_losses': train_losses,\n",
    "       'val_accuracies': val_accuracies,\n",
    "       'success': best_val_accuracy >= 0.999,\n",
    "       'X_test': X_test,\n",
    "       'y_test': y_test,\n",
    "       'y_pred': predicted.cpu().numpy()\n",
    "   }\n",
    "\n",
    "def plot_confusion_matrix(result):\n",
    "   \"\"\"Plot confusion matrix for the test results\"\"\"\n",
    "   operations = ['Addition', 'Subtraction', 'Multiplication', 'Division']\n",
    "   \n",
    "   # Calculate confusion matrix\n",
    "   cm = confusion_matrix(result['y_test'], result['y_pred'])\n",
    "   \n",
    "   # Plot\n",
    "   plt.figure(figsize=(10, 8))\n",
    "   sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=operations, yticklabels=operations)\n",
    "   plt.ylabel('True Label')\n",
    "   plt.xlabel('Predicted Label')\n",
    "   plt.title('Confusion Matrix')\n",
    "   plt.show()\n",
    "\n",
    "# Test the best configuration from previous run\n",
    "print(\"Training the best configuration for visualization\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Best configuration\n",
    "layer1 = 128\n",
    "layer2 = 64 \n",
    "layer3 = 32\n",
    "\n",
    "result = train_and_evaluate(layer1, layer2, layer3)\n",
    "analyze_activations(result['model'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(result)\n",
    "\n",
    "# Show summary\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"Configuration Results:\")\n",
    "print(\"-\" * 120)\n",
    "print(f\"{'Layer 1':^8} | {'Layer 2':^8} | {'Layer 3':^8} | {'Epochs':^8} | {'Val Accuracy':^15} | {'Test Accuracy':^15} | {'Success':^10}\")\n",
    "print(\"-\" * 120)\n",
    "print(f\"{result['layer1']:^8} | {result['layer2']:^8} | {result['layer3']:^8} | {result['epochs']:^8} | {result['val_accuracy']:.4f}{' ':^9} | {result['test_accuracy']:.4f}{' ':^9} | {'✓' if result['success'] else '×'}\")\n",
    "\n",
    "print(\"\\nBest Configuration:\")\n",
    "print(f\"- Layer 1: {result['layer1']} neurons\")\n",
    "print(f\"- Layer 2: {result['layer2']} neurons\")\n",
    "print(f\"- Layer 3: {result['layer3']} neurons\")\n",
    "print(f\"- Trained for {result['epochs']} epochs\")\n",
    "print(f\"- Validation Accuracy: {result['val_accuracy']:.4f}\")\n",
    "print(f\"- Test Accuracy: {result['test_accuracy']:.4f}\")\n",
    "print(f\"- Success: {'Yes' if result['success'] else 'No'}\")\n",
    "\n",
    "print(\"\\nActivation function analysis:\")\n",
    "analyze_activations(result['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "1. Im unable to go beyond 98% accuracy with the current model.\n",
    "2. Its funny how with so many neurons, still the model cant get 100% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
